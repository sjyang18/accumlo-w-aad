---
- name: changes the existing hadoop configs with kerberos
  hosts: hadoop
  gather_facts: yes
  become: no
  tasks:
    - import_tasks: tasks/common_vars.yml

    - name: Set keberos keytab file and service principal name
      set_fact:
        hadoop_service_principal_keytabfile: "{{ keytabs_deployment_dir }}/{{ service_principal_login }}.keytab"
        hadoop_service_principal: "{{ service_principal_login }}/_HOST@{{ realm_name }}"
        hadoop_service_principal_w_fqdn: "{{ service_principal_login }}/{{ ansible_fqdn }}@{{ realm_name }}"
        http_service_principal_keytabfile: "{{ keytabs_deployment_dir }}/HTTP.keytab"
        http_service_principal: "HTTP/_HOST@{{ realm_name }}"

    - name: Generate hdfs_zkfc.jaas
      template:
        src=conf/hdfs_zkfc.jaas.j2
        dest='{{ hadoop_home }}/etc/hadoop/hdfs_zkfc.jaas'

    - name: Update HDFS_ZKFC_OPTS with Kerberos setting
      blockinfile:
        path: '{{ hadoop_home }}/etc/hadoop/hadoop-env.sh'
        insertafter: EOF
        marker: "# {mark} ANSIBLE MANAGED BLOCK for Kerberos"
        block: |
          export HDFS_ZKFC_OPTS="-Djava.security.auth.login.config={{ hadoop_home }}/etc/hadoop/hdfs_zkfc.jaas -Dzookeeper.sasl.client=true -Dzookeeper.sasl.client.username={{ service_principal_login }} -Dzookeeper.sasl.clientconfig=Client ${HDFS_ZKFC_OPTS}"

    - name: update etc/hadoop/core-site.xml with Kerberos setting
      blockinfile:
        path: '{{ hadoop_home }}/etc/hadoop/core-site.xml'
        insertbefore: '\<\/configuration\>$'
        marker: "<!-- {mark} ANSIBLE MANAGED BLOCK for Kerberos -->"
        block: |
          <property>
              <name>hadoop.security.authentication</name>
              <value>kerberos</value>
          </property>
          <property>
              <name>hadoop.security.authorization</name>
              <value>true</value>
          </property>
          <property>
                <name>hadoop.rpc.protection</name>
                <value>authentication,privacy</value>
          </property>

          <property>
                <name>hadoop.proxyuser.hdfs.groups</name>
                <value>*</value>
          </property>

          <property>
              <name>hadoop.proxyuser.hdfs.hosts</name>
              <value>*</value>
          </property>

          <property>
            <name>hadoop.proxyuser.HTTP.groups</name>
            <value>users</value>
          </property>

          <property>
            <name>hadoop.proxyuser.yarn.groups</name>
            <value>*</value>
          </property>

          <property>
            <name>hadoop.security.auth_to_local</name>
            <value>
          RULE:[1:$1@$0](.*@{{ realm_name }})s/@.*///L
          RULE:[2:$1@$0]({{ domain_admin_username }}@{{ realm_name }})s/.*/{{ domain_admin_username }}/
          DEFAULT</value>
          </property>

          <property>
                <name>hadoop.proxyuser.yarn.hosts</name>
                <value>{{ groups['resourcemanager'][0] }}.{{ domain_name }},{{ groups['resourcemanager'][1] }}.{{ domain_name }}</value>
          </property>
   
    - name: update etc/hadoop/hdfs-site.xml with Kerberos setting
      blockinfile:
        path: '{{ hadoop_home }}/etc/hadoop/hdfs-site.xml'
        insertbefore: '\<\/configuration\>$'
        marker: "<!-- {mark} ANSIBLE MANAGED BLOCK for Kerberos -->"
        block: |
          <!-- Namenode -->

          <property>
                <name>dfs.block.access.token.enable</name>
                <value>true</value>
          </property>

          <property>
                <name>dfs.namenode.kerberos.principal</name>
                <value>{{ hadoop_service_principal }}</value>
          </property>

          <property>
                <name>dfs.namenode.keytab.file</name>
                <value>{{ hadoop_service_principal_keytabfile }}</value>
          </property>

          <property>
                <name>dfs.namenode.kerberos.internal.spnego.principal</name>
                <value>{{ http_service_principal }}</value>
          </property>

          <property>
                <name>dfs.web.authentication.kerberos.keytab</name>
                <value>{{ http_service_principal_keytabfile }}</value>
          </property>
          <property>
                <name>dfs.http.policy</name>
                <value>HTTPS_ONLY</value>
          </property>

          <property>
              <name>dfs.webhdfs.enabled</name>
              <value>true</value>
          </property>

          <property>
              <name>dfs.encrypt.data.transfer</name>
              <value>true</value>
          </property>

          <!-- JournalNode -->

          <property>
                <name>dfs.journalnode.kerberos.principal</name>
                <value>{{ hadoop_service_principal }}</value>
          </property>

          <property>
                <name>dfs.journalnode.keytab.file</name>
                <value>{{ hadoop_service_principal_keytabfile }}</value>
          </property>

          <property>
                <name>dfs.journalnode.kerberos.internal.spnego.principal</name>
                <value>{{ http_service_principal }}</value>
          </property>

          <property>
                <name>dfs.journalnode.https-address</name>
                <value>0.0.0.0:8481</value>
          </property>

          <!-- DataNode -->

          <property>
                <name>dfs.datanode.data.dir.perm</name>
                <value>750</value>
          </property>

          <property>
                <name>dfs.datanode.address</name>
                <value>0.0.0.0:1039</value>
                <description> This must be non-privileged port (i.e. > 1024) for
                SASL to authenticate Data Transfer Protocol (DTP) </description>
          </property>

          <property>
                <name>dfs.datanode.https.address</name>
                <value>0.0.0.0:50075</value>
          </property>

          <property>
                <name>dfs.datanode.kerberos.principal</name>
                <value>{{ hadoop_service_principal }}</value>
          </property>

          <property>
                <name>dfs.datanode.keytab.file</name>
                <value>{{ hadoop_service_principal_keytabfile }}</value>
          </property>

          <property>
              <name>dfs.encrypt.data.transfer</name>
              <value>true</value>
          </property>

          <property>
                <name>dfs.encrypt.data.transfer.cipher.suites</name>
                <value>AES/CTR/NoPadding</value>
          </property>

          <property>
                <name>dfs.data.transfer.protection</name>
                <value>authentication,privacy</value>
          </property>

          <!-- WebHDFS -->

          <property>
                <name>dfs.web.authentication.kerberos.principal</name>
                <value>{{  http_service_principal }}</value>
          </property>

          <property>
                <name>dfs.web.authentication.kerberos.keytab</name>
                <value>{{ http_service_principal_keytabfile }}</value>
          </property>
