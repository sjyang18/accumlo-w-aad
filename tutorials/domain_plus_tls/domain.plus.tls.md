# Azure AD (AAD) Domain-joined & TLS enabled Accumulo cluster
This tutorial walks thru and captures the conversion steps from a plain accumulo with fluo-mucho to a AAD domain-joined & TLS enabled Accumulo cluster. We assume that you have already setup your own AAD and AAD domain services with secured ldap enabled. And, your flu-muchos has the internal patch (fluo-muchos includes the internal patch (https://dev.azure.com/AZGlobal/AG%20E2E%5E2%20-%20Secure%20Data%20Estate/_git/fluo-muchos/pullrequest/2794)) to enable TLS. Note that this tutorial skips Kerberos-enabling for simplicity, but follow-up tasks may turn the result into a Kerberos enabled cluster as well. 

## Launch & Set up an Accumulo cluster with fluo-mucho
Your muchos.properties should have proxy_hostname, azure_proxy_hostname. This proxy host would have ansible playbooks and the host file to be modified for conversion.

```
# change according to your python3 virtual environment path
source ~/p36env/bin/activate
./bin/muchos launch -c accucluster3
./bin/muchos setup -c accucluster3
``` 

## Stop cluster (i.e. Azure VMSS) thru Azure Portal
This steps is needed in order to take effect of VNET peering, and update DNS server of your Accumulo cluster VNET. From Azure portal, find your Accumulo cluster's VMSS and stop.

![Image](images/stop_cluster.jpg)


## VNET peering to AAD domain services VNET
Go to your AAD domain service VNET, and create a bi-directional VNET peering. 
![Image](images/vnetpeering.jpg)

## Add DNS servers to your Accumulo cluster VNET
The DNS servers are from your AAD domain services. Find from its portal and add them to your Accumulo cluster vnet.

![Image](images/addDNS.jpg)

## Start cluster thru Azure Portal
Start the VMSS of your Accumulo cluster from Azure Portal.
![Image](images/start_cluster.jpg)

## Edit ansible inventory file and group_vars/all
SSH/log into your proxy or bastion host. The ansible inventory file is ~/ansible/conf/hosts, generated by fluo-mucho setup command. Add the following variables with your values (replacing XXX with yours) to the invetory file.

```
[all:vars]
domain_name=XXX.onmicrosoft.com
cluster_domain_name={{ domain_name }}
realm_name={{ domain_name |upper }}
domain_dn=DC=XXX,DC=onmicrosoft,DC=com
domain_workgroup=XXX
custom_ou_name=XXX
domain_admin_username=XXX
domain_admin_full_username='{{ domain_admin_username }}@{{ realm_name }}'
ldap_host_ip_address=10.0.0.5
ldap_hostname=ldaps.XXX.onmicrosoft.com
ldap_uri=ldaps://{{ ldap_hostname }}
ldap_binddn='CN={{ domain_admin_username }},OU=AADDC Users,{{ domain_dn }}'
encoded_user_init_password=:~~~~~~~~~~~~~
decoded_user_init_password=XXXXXX
```
## Git clone this repo to get domain utility playbooks 
Inside the proxy node, run to get this repo.

```
sudo yum install git
git clone https://github.com/sjyang18/accumulo-w-aad.git
```

## Domain-join your cluster with ansible-playbook commands

The following ansible playbook executions would prompt the password of the domain_admin_username and make updates to Azure AD domain services using ldap.

```
ansible-playbook -i ~/ansible/conf/hosts accumulo-w-aad/ansible/ldap_config.yml

ansible-playbook -i ~/ansible/conf/hosts accumulo-w-aad/ansible/ldap_addou.yml

ansible-playbook -i ~/ansible/conf/hosts accumulo-w-aad/ansible/join_domain.yml

```

## Reconfigure Accumulo cluster with FQDN and TLS

Add the following variables to your host file, if you don't have. Note that we provided the flexibility of turning off TLS at the zookeeper layer. You explictly set enable_zookeeper_tls, only if your Accumulo version has this patch (https://github.com/apache/accumulo/pull/1883).
If your Accumulo version does not have that patch, comment out enable_zookeeper_tls, thus TLS is only enabled only in Hadoop and Accumulo side.  

```
# this variable should be the same as domain_name vairlabe used before. 
cluster_domain_name = XXX.onmicrosoft.com
enable_tls = True
#enable_zookeeper_tls = True
```

Then, copy ~/ansible/site.yml to ~/ansible/domain-site.yml. Open domain-site.yml and remove importing common.yml. This file reset /etc/hosts files which will remove FQDN host names, so we drop that execution and re-run zookeeper.yml, haddoop.yml, and accumulo.yml only. 

```
ansible-playbook -i ansible/conf/hosts ansible/domain-site.yml -e "target_host_group=all azure_proxy_host=bastion"
```

## Generate Self-signed certifcates and Enable TLS
Run the enable_tls.yml ansible playbook to generate self-signed certificates with the domain name.

```
ansible-playbook -i ansible/conf/hosts ansible/enable_tls.yml
```

## Verify certificates
SSH/Login into the first name node and verify that you have certificates of all the nodes of your cluster in truststore with FQDN. For example,

```
[azureuser@accucluster3-0 ~]$ keytool -list -keystore /opt/muchos/install/ssl/truststore.jks
Enter keystore password:
Keystore type: PKCS12
Keystore provider: SUN

Your keystore contains 8 entries

accucluster3-0.XXX.onmicrosoft.com, Feb 2, 2021, trustedCertEntry,
Certificate fingerprint (SHA-256): 78:1B:22:34:82:20:F5:44:B4:3E:5A:E6:BB:D1:FF:1B:6B:E3:70:1E:51:4E:BD:15:D7:1A:64:0F:FF:41:29:34
accucluster3-1.XXX.onmicrosoft.com, Feb 2, 2021, trustedCertEntry,
Certificate fingerprint (SHA-256): AD:45:E4:5E:22:2B:8F:A7:B6:24:C8:77:26:A4:FE:30:C9:43:E8:1E:84:24:FD:9B:E2:02:CA:21:45:58:75:78
accucluster3-2.XXX.onmicrosoft.com, Feb 2, 2021, trustedCertEntry,
Certificate fingerprint (SHA-256): 92:0F:A5:52:22:31:D7:2D:DC:73:A6:07:C4:8B:54:74:A4:62:9D:AD:27:CD:AC:0C:EB:20:A8:97:FA:F4:08:5A
accucluster3-3.XXX.onmicrosoft.com, Feb 2, 2021, trustedCertEntry,
Certificate fingerprint (SHA-256): D9:D4:E7:95:CA:EA:CD:FE:35:6B:8F:2A:91:C1:38:0E:CB:80:F5:4F:5F:05:FF:56:56:1D:84:A8:17:6F:9C:9F
accucluster3-4.XXX.onmicrosoft.com, Feb 2, 2021, trustedCertEntry,
Certificate fingerprint (SHA-256): B8:75:98:9D:08:39:55:61:E0:26:67:0F:95:51:2D:41:F7:FC:B6:3E:1E:09:C6:DC:C4:AB:2B:6E:FA:79:1D:D0
accucluster3-5.XXX.onmicrosoft.com, Feb 2, 2021, trustedCertEntry,
Certificate fingerprint (SHA-256): AD:59:61:41:4F:C1:39:AB:BC:11:8C:BA:59:35:18:3A:B0:90:64:D9:2A:E4:A8:D8:F1:69:2C:60:A4:9D:B4:50
accucluster3-6.XXX.onmicrosoft.com, Feb 2, 2021, trustedCertEntry,
Certificate fingerprint (SHA-256): 9F:17:0F:80:30:B9:2D:E3:91:02:C2:FD:3B:BE:7C:11:C1:07:32:8E:90:FE:33:C6:A9:48:34:8E:73:91:91:01
accucluster3-8.XXX.onmicrosoft.com, Feb 2, 2021, trustedCertEntry,
Certificate fingerprint (SHA-256): 40:D9:A4:2B:7D:46:37:9D:C4:86:8C:D4:FF:FC:93:A8:FB:91:3E:F5:C5:B4:64:FF:40:C7:85:F1:A6:F0:4E:63

```
If this is not case, verify if `'hostname -f'` will return FQDN host name and `/etc/hosts` file contains the FQDN for each host like:
```
172.19.0.5  accucluster3-0.XXX.onmicrosoft.com accucluster3-0
```

## Zookeepers, Verification, and Debugging
In the following, I am capturing the each command I run to verify the TLS enabling and services running, rather than running a playbook. I recommend that you would do the same as verification process.
Log into each zookeeper node, start the zookeeper service, and verify the connectivity.

```
# on each zookeeper node you find in the inventory file
zkServer.sh start
```

Test zookeeper connectivity. For example,

```
zkCli.sh -server accucluster3-0.XXX.onmicrosoft.com:2181

Connecting to accucluster3-0.XXX.onmicrosoft.com:2181
Welcome to ZooKeeper!
JLine support is enabled
[zk: accucluster3-0.XXX.onmicrosoft.com:2181(CONNECTING) 0]
WATCHER::

WatchedEvent state:SyncConnected type:None path:null

[zk: accucluster3-0.XXX.onmicrosoft.com:2181(CONNECTED) 0] ls /
[accumulo, hadoop-ha, tracers, zookeeper]

```

If you see the error in connectivity to your zookeeper nodes, verfiy the zookeeper configurations. Verify that all host name references are using FQDN. 

```
# this must has server list like server.1, server.2, and server.3 with values.
less /opt/muchos/install/apache-zookeeper-3.5.9-bin/conf/zoo.cfg
# this should have server id like 1 ,2 , or 3
less /var/data/data2/zookeeper/myid
```

For debugging, you will see zookeeper log in 
```
ls -al /var/data/data2/logs/zookeeper/zookeeper-azureuser-server-*.log
```

## Hadoop, Verification, and Debugging
Start hadoop dfs services on one of name nodes, and verify if hadoop dfs services are up. Verify that all host name references in hadoop configurations are using FQDN. 

```
start-dfs.sh
jps -m
hdfs dfs -ls /
hdfs haadmin -getServiceState nn1
hdfs haadmin -getServiceState nn2
```

You should have at least one active name node. And, check if DFSZKFailoverController is in the output of `'jps -m'`. If not, it mean somethig to do with Zookeeper connectivities. Depending on whehter you enable TLS at zookeeper side, check the hadoop side configuration. For example, if you have enabled TLS at zookeeper side, you shoud see the following environmental variables set in `/opt/muchos/install/hadoop-3.3.0/etc/hadoop/hadoop-env.sh`.

```
CLIENT_JVMFLAGS="-Dzookeeper.clientCnxnSocket=org.apache.zookeeper.ClientCnxnSocketNetty \
-Dzookeeper.client.secure=true \
-Dzookeeper.ssl.keyStore.location=/opt/muchos/install/ssl/host-keystore.jks \
-Dzookeeper.ssl.keyStore.password=hadoop2 \
-Dzookeeper.ssl.trustStore.location=/opt/muchos/install/ssl/truststore.jks \
-Dzookeeper.ssl.trustStore.password=hadoop2"

export HDFS_ZKFC_OPTS="-server -XX:+UseG1GC -XX:MaxGCPauseMillis=400 -XX:InitiatingHeapOccupancyPercent=35 -XX:ParallelGCThreads=8 -XX:ConcGCThreads=2 -Xms4G -Xmx4G -verbose:gc -Xlog:gc:/var/data/data2/logs/hadoop/gc-zkfc.log-`date +'%Y%m%d%H%M'`:time,uptime:filecount=10,filesize=100M -XX:ErrorFile=/var/data/data2/logs/hadoop/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/var/data/data2/logs/hadoop $CLIENT_JVMFLAGS"
```

Login into one of data node and verify that data node is up.
```
[azureuser@accucluster3-4 ~]$ jps -m
13121 Jps -m
22120 DataNode
```

Hadoop side logs are availalbe for debugging.
```
ls -al /var/data/data2/logs/hadoop/
```

## Accumulo, Verfication, and Debugging
Again, verify zookeer connect references are using FQDN in Accumulo configuration. On the first name node, start up your Accumulo cluster.
```
[azureuser@accucluster3-0 ~]$ accumulo-cluster start
Starting tablet servers ........ done
Starting master on accucluster3-0
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/muchos/install/accumulo-2.1.0-SNAPSHOT/lib/log4j-slf4j-impl-2.14.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/muchos/install/apache-zookeeper-3.5.9-bin/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Starting tserver on accucluster3-4
2021-02-03T00:13:39,226 [conf.SiteConfiguration] INFO : Found Accumulo configuration on classpath at /opt/muchos/install/accumulo-2.1.0-SNAPSHOT/conf/accumulo.properties
2021-02-03T00:13:41,607 [server.ServerUtil] INFO : Attempting to talk to zookeeper
2021-02-03T00:13:42,117 [server.ServerUtil] INFO : ZooKeeper connected and initialized, attempting to talk to HDFS
2021-02-03T00:13:42,137 [server.ServerUtil] INFO : Connected to HDFS
Starting tserver on accucluster3-6
Starting tserver on accucluster3-5
Starting tserver on accucluster3-8
Starting tserver on accucluster3-3
Starting gc on accucluster3-0
Starting tracer on accucluster3-0
Starting monitor on accucluster3-0
[azureuser@accucluster3-0 ~]$ Starting gc on accucluster3-1
Starting tracer on accucluster3-1
Starting master on accucluster3-1
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/muchos/install/accumulo-2.1.0-SNAPSHOT/lib/log4j-slf4j-impl-2.14.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/muchos/install/apache-zookeeper-3.5.9-bin/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
2021-02-03T00:13:52,048 [conf.SiteConfiguration] INFO : Found Accumulo configuration on classpath at /opt/muchos/install/accumulo-2.1.0-SNAPSHOT/conf/accumulo.properties
2021-02-03T00:13:55,469 [server.ServerUtil] INFO : Attempting to talk to zookeeper
2021-02-03T00:13:56,104 [server.ServerUtil] INFO : ZooKeeper connected and initialized, attempting to talk to HDFS
2021-02-03T00:13:56,162 [server.ServerUtil] INFO : Connected to HDFS

```

Using ashell command, run basic tests.
```
[azureuser@accucluster3-0 ~]$ ashell
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/muchos/install/accumulo-2.1.0-SNAPSHOT/lib/log4j-slf4j-impl-2.14.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/muchos/install/apache-zookeeper-3.5.9-bin/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Loading configuration from /opt/muchos/install/accumulo-2.1.0-SNAPSHOT/conf/accumulo-client.properties
2021-02-03T00:14:38,187 [tracer.AsyncSpanReceiver] INFO : host from config: accucluster3-0
2021-02-03T00:14:38,188 [tracer.AsyncSpanReceiver] INFO : starting span receiver with hostname accucluster3-0

Shell - Apache Accumulo Interactive Shell
-
- version: 2.1.0-SNAPSHOT
- instance name: muchos
- instance id: 22d2e080-53d9-4160-998c-a6f829e11e20
-
- type 'help' for a list of available commands
-
root@muchos> createtable test4
root@muchos test4> insert a b c d
root@muchos test4> flush -w
2021-02-03T00:15:39,920 [shell.Shell] INFO : Flush of table test4  completed.
root@muchos test4> droptable test4
droptable { test4 } (yes|no)? yes
Table: [test4] has been deleted.
```

Like other service logs, Accumulo logs are :
```
ls -al /var/data/data2/logs/accumulo/
```












